{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Review.ipynb","provenance":[],"authorship_tag":"ABX9TyNdnFaemZZL0vSMswpTfSYm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aN5gwMcUH0sl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yy7WHpmXH_Ra"},"source":["# Final Review\r\n","By: Pieter\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"QyfY8uuqIKKe"},"source":["# Assignment Quick Look up\r\n","\r\n","1. Supervised learning, Linear models, and Loss functions\r\n","2. Maximum Likelihood\r\n","3. Classification with Logistic Regression\r\n","4. Confidence Intervals & The Bootstrap\r\n","5. Model Selection & Cross Validation\r\n","6. Regularization\r\n","7. Midterm\r\n","8. Random Forest\r\n","9. Neural Networks \r\n","10. Autoencoder\r\n","11. Clusters\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"A2cPJyY8BaDa"},"source":["# Assumptions\r\n","\r\n","Assume the standard deviation obtained from using median as prediction is good estimate for noise present in data. Likely an overestimation."]},{"cell_type":"markdown","metadata":{"id":"PRLo-Y5yce_n"},"source":["# **Data Manipulation**\r\n","\r\n","### Importing Data\r\n","\r\n","```python\r\n","df = pd.read_csv('creditcard.csv')\r\n","df.head()\r\n","```\r\n","\r\n","### Cleaning Data\r\n","\r\n","Dropping Data\r\n","```python \r\n","# Columns\r\n","X = df.drop('Class', axis='columns').values\r\n","\r\n","# Multiple Columns\r\n","model_data = model_data.drop(columns=[\"DeviceName\", \"Outdoor_Humidity\", \"Discharge_Temperature\"])\r\n","\r\n","# Drop NA \r\n","model_data.dropna()\r\n","```\r\n","\r\n","Covert Categorical Data into Numerical Data\r\n","```python\r\n","# In order to get dummies, you can convert the categorical data to categorical type\r\n","# with a specific \r\n","model_data['work_rate_att'] = pd.Categorical(model_data.work_rate_att, categories=['Low','Medium','High'])\r\n","model_data['work_rate_def'] = pd.Categorical(model_data.work_rate_def, categories=['Low','Medium','High'])\r\n","model_data['preferred_foot'] = pd.Categorical(model_data.preferred_foot, categories = ['Left','Right'])\r\n","\r\n","# Dummies, dropping the first category - Allows for more efficient data use\r\n","# Example: Use 2 bits instead of 3 to represent Low, Medium, High\r\n","model_data = pd.get_dummies(model_data, drop_first=True)\r\n","\r\n","model_data.head()\r\n","```\r\n","\r\n","\r\n","### Split Test/Train Data\r\n","```python\r\n","# Split Data into Training and Testing Data\r\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = test_size, random_state = 0)\r\n","```\r\n","\r\n","### Data Frame Building\r\n","\r\n","```python\r\n","# Build Data Frame to extract Coef Columns by Name\r\n","p = PolynomialFeatures(degree=2).fit(x_test)\r\n","features = pd.DataFrame(ridge_coefs, columns=p.get_feature_names(x_data.columns))\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"PYUfrtlzL9Sw"},"source":["Functions \r\n","\r\n","#### $R^2$\r\n","```python\r\n","def R_Squared(y_true, y_pred):\r\n","    rss = sum((y_true - y_pred)**2) \r\n","    tss = sum(( y_true - y_true.mean())**2)\r\n","    r2 = 1 - rss/tss\r\n","    return r2\r\n","```\r\n","\r\n","#### $RSS$\r\n","Residual Sum of Squares\r\n","```python\r\n","def RSS(y_true, y_pred):\r\n","    residual_sum_of_squares = sum((y_true - y_pred)**2) \r\n","    return residual_sum_of_squares\r\n","\r\n","```\r\n","\r\n","#### $TSS$\r\n","Total Sum of Squares\r\n","```python\r\n","def TSS(y_true):\r\n","    total_sum_of_squares = sum(( y_true - y_true.mean())**2) \r\n","    return total_sum_of_squares\r\n","\r\n","```\r\n","\r\n","#### $MAE$\r\n","Mean Average Error\r\n","```python\r\n","def mae(y,ypred):\r\n","    return abs(y - ypred).mean()\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"5-_bj3ARHTn6"},"source":["# **Graphs**\r\n","\r\n","### Creating Line of best Fit \r\n","\r\n","```python\r\n","# Create x value that spans range of data\r\n","xp = np.linspace(66, 80, 30)\r\n","\r\n","# Predict y values using model\r\n","yp = model.predict(xp)\r\n","\r\n","# Plot data\r\n","import matplotlib.pyplot as plt\r\n","plt.plot(xp,yp)\r\n","```\r\n","\r\n","### Scatter \r\n","\r\n","```python\r\n","# MatLab\r\n","def scatter_plot(x_data_pts, y_data_pts):\r\n","  # Plot\r\n","  fig, ax = plt.subplots(dpi = 120)\r\n","  fig.set_facecolor('white')\r\n","\r\n","  # Plot Formatting \r\n","  ax.set_title('X Title vs. Y Title')\r\n","  ax.set_xlabel('X Title')\r\n","  ax.set_ylabel('Y Title')\r\n","\r\n","  # Plot Data\r\n","  # Label is for the legend\r\n","  ax.plot(x_data_pts, y_data_pts, 'k.', label='Data Set Name')\r\n","\r\n","  # Legend\r\n","  ax.legend(loc=1)\r\n","  plt.show()\r\n","```\r\n","\r\n","```python \r\n","import seaborn as sns\r\n","df_test=pd.read_csv('hockey_draftees_test.csv')\r\n","\r\n","# Seaborn\r\n","ax=sns.scatterplot(x=df_test.ht,y=df_test.wt)\r\n","ax.set_xlabel('Height')\r\n","ax.set_ylabel('Weight')\r\n","\r\n","```\r\n","\r\n","### Scatter Density\r\n","\r\n","LAB 4 Q5\r\n","```python \r\n","# Seaborn\r\n","import seaborn as sns\r\n","sns.jointplot(x=params[:,0],y=params[:,1])\r\n","\r\n","```\r\n","\r\n","### Histogram\r\n","\r\n","LAB 4 Q6\r\n","```python\r\n","# Matlab\r\n","import matplotlib.pyplot as plt\r\n","plt.hist(params[:,1], edgecolor = 'white', density=True)\r\n","```\r\n","\r\n","```python\r\n","hist = sns.distplot(slope)\r\n","\r\n","hist.set_title(\"Slope Distribution\")\r\n","hist.set_xlabel(\"Slope Value\")\r\n","hist.set_ylabel(\"Probability\")\r\n","hist.set_facecolor('white')\r\n","```\r\n","\r\n","### Histogram with a line\r\n","LAB 6 #2\r\n","```python\r\n","ax = sns.distplot(Xtrain.stamina,\r\n","                 bins=50,\r\n","                 kde=True,\r\n","                 color='skyblue',\r\n","                 hist_kws={\"linewidth\": 15,'alpha':1})\r\n","ax.set(xlabel='stamina', ylabel='frequency', title=\"Before Standardization\")\r\n","```\r\n","\r\n","### Distribution Plot\r\n","LAB 5 Q1\r\n","```python\r\n","# Seaborn\r\n","sns.distplot(x)\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"yEXdDTP1JfYq"},"source":["# **LAB 1**\r\n","\r\n","## Loss Functons\r\n","\r\n","### OLS\r\n","Ordinary Least Square Function\r\n","\r\n","$$ RSS = \\sum_{i=1}^N( y_a(i) - y_p(i))^2 $$\r\n","\r\n","Take the square of the residuals between the actual and the predicted vaules\r\n","\r\n","**Written:** This is because OLS minimized the RSS, and therefore maximizes R2.\r\n","\r\n","```python\r\n","\r\n","def linearModelLossRSS(b, X, y):\r\n","\r\n","    yp = X @ b\r\n","    l = sum(np.square(y-yp))\r\n","    \r\n","    grad = (X.T @ (y-yp)) * -2\r\n","    return l, grad\r\n","  \r\n","```\r\n","\r\n","\r\n","### LAD \r\n","Least Absolute Deviations\r\n","\r\n","$$ LAD = \\sum_{i=1}^N| y_a(i) - y_p(i) | $$\r\n","\r\n","\r\n","Take the absolute values of all the residuals between the actual and the predicted values\r\n","\r\n","**Written:**The r squared value of the LAD model is lower since it put less emphasis on outliers compared to RSS. \r\n","\r\n","Putting less emphasis on the outliers will make the line fit local data better but will have a worse global data fit (r squared value)\r\n","\r\n","```python\r\n","def linearModelLossLAD(b, X, y):\r\n","    \r\n","    yp = X @ b\r\n","    l = sum(abs(y-yp))\r\n","    grad = -np.sign((y-yp)) @ X    \r\n","    return l, grad\r\n","```\r\n","\r\n","### Comparison \r\n","\r\n","| OLS | LAD |\r\n","|--|-|\r\n","|Not very Robust | Robust |\r\n","|Stable Solution| Unstable Solution|\r\n","| One Solution | Possibly Multiple Solutions|\r\n","\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"RXup9URYZuiL"},"source":["# **LAB 2**\r\n","\r\n","## Likelihood\r\n","\r\n","- Measure the goodness of fit of a statistical model \r\n","- Given data how well does the distribution fit the data?\r\n","- Data is fixed\r\n","\r\n","#### Probabilty\r\n","- The chances of an event of occuring \r\n","- Given a distribution what is the chance of the event occuring\r\n","- Distribution is fixed\r\n","\r\n","\r\n","### Maximum Likelihood\r\n","Maximum likelihood estimation (MLE) is a method of estimating the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is most probable. \r\n","\r\n","\r\n","### Possion Distribution\r\n","\r\n","The poisson distribution is a discrete probability distribution often used to describe count-based data, like how many snowflakes fall in a day.\r\n","\r\n","$$\\ell(\\lambda; \\mathbf{y}) = -\\sum_{i=1}^N\\Bigg( y_{i}\\cdot \\ln(\\lambda) - \\lambda - \\ln(y_i!) \\Bigg)$$\r\n","\r\n","```python\r\n","\r\n","def poissonNegLogLikelihood(lam,y):\r\n","    \r\n","    # Read up on the gamma function to make sure you get the likelihood right!\r\n","    \r\n","    #neg_log_lik = -sum(np.log(lam)* y - lam)\r\n","    neg_log_lik = -np.sum(y * np.log(lam) - lam - gammaln(y+1))\r\n","    return neg_log_lik\r\n","\r\n","\r\n","def poissonRegressionNegLogLikelihood(b, X, y):\r\n","    #Enter the expression for lambda as shown above!\r\n","    lam = np.exp(X.dot(b))\r\n","           \r\n","    # Use poissonNegLogLikelihood to compute the likelihood\r\n","    neg_log_lik = poissonNegLogLikelihood(lam ,y)\r\n","    return neg_log_lik\r\n","\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"btbF9ZskVTx1"},"source":["# **LAB 3**\r\n","\r\n","### **Regresions**\r\n","\r\n","### **Linear Regression:**\r\n","Creates a line of best fit\r\n","\r\n","```python\r\n","linear_poly_pipeline = Pipeline([('poly_features', PolynomialFeatures(degree=2)),\r\n","                                  ('LR', LinearRegression())])\r\n","linear_pipeline.fit(x_train, y_train)\r\n","\r\n","```\r\n","\r\n","\r\n","### **Logistic Regression:**\r\n","\r\n","Logistic Regression is used to make a true / false outcome based based on input parameters \r\n","\r\n","An outcome is marked positive / true if the probability of likehood is greater than 0.50. The threshold of 0.50 can be raised or lowered if required\r\n","\r\n","Uses maximum likehood to determine best fit\r\n","\r\n","Threshold can be editted to the user's design. A common threshold is one of 0.5 (50%). However, the threshold can be changed to fit certain needs. For example, it is very important to identify patients with cancer the threshold might be set to 0.3. This will result in more false positive than flase negetives. Ie: It is better to double check that the patient has cancer than leave it untreated. \r\n","\r\n","```python\r\n","LogisticRegression(solver='lbfgs',penalty = 'none',max_iter=10000)\r\n","\r\n","# True / False Predict\r\n","yp_ =lr_amount.predict(xp)\r\n","\r\n","# Probabilty Predict\r\n","yp=lr_amount.predict_proba(xp)\r\n","\r\n","# Plotting \r\n","sns.lineplot(xp,yp)\r\n","```\r\n","\r\n","### **ROC** | Reciever Operator Characteristic\r\n","\r\n","Plots the Rate of False Positive to True Positive \r\n","\r\n","Percentage of Cancer samples labeled correctly as Cancer (True Negative)\r\n","$$ True Positive Rate = \\frac{True Positives}{True Positives + False Negatives} $$\r\n","\r\n","Percentage of Not Cancer samples labeled incorrectly as Cancer (False Positive)\r\n","$$ False Positive Rate = \\frac{False Positives}{True Positives + True Negatives} $$\r\n","\r\n","ROC will end at 1,1 becuase if everything is cancer all the cancer samples will be labelled correctly. However, this means all the not cancer samples will be incorrectly labelled\r\n","\r\n","Tells the us the optimal threshold\r\n","\r\n","\r\n","* True Positive: Cancer Samples Labeled as Cancer\r\n","* False Negative: Cancer Sample Labeled as Not Cancer\r\n","* True Negative: Not Cancer Sample Labeled as Not Cancer \r\n","* False Positive: Not Cancer Sample Labeled as Cancer \r\n","\r\n","\r\n","Precision:\r\n","\r\n","Is the proportion of positive results that were correctly classified\r\n","$$ Precision = \\frac{True Positives}{True Positives + False Positive} $$\r\n","\r\n","Recall: (Same as True Positive Rate)\r\n","\r\n","Percentage of Cancer samples labeled correctly as Cancer (True Negative)\r\n","\r\n","$$ Recall= \\frac{True Positives}{True Positives + False Negatives} $$\r\n","\r\n","Note: Look at a confusion matrix if you are confused. It is easier to understand\r\n","\r\n","### **AUC** | Area Under the Curve\r\n","\r\n","AUC makes it easy to compare one ROC curve to another to determine which one is better. A higher AUC the better it is at properly classifying a sample.\r\n","\r\n","One ROC could use a Random Forest while another ROC could use Logistic Regression. An AUC would tell us which ROC is better\r\n","\r\n","```python\r\n","# Import \r\n","from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\r\n","\r\n","# ROC for all-variable classifier\r\n","\r\n","# Predict Using Model\r\n","ytest_prob = lr_all.predict_proba(Xtest)\r\n","\r\n","# False Positive Rate, True Positive Rate\r\n","fpr, tpr, _ = roc_curve(ytest, ytest_prob[:,1], pos_label=1)\r\n","\r\n","# Plot\r\n","ax=sns.lineplot(fpr,tpr)\r\n","ax.set(xlabel=\"FPR\",ylabel=\"TPR\")\r\n","\r\n","# AUC\r\n","auc(fpr,tpr)\r\n","\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"OVTYIrO-boxd"},"source":["# **LAB 4**\r\n","\r\n","\r\n","### Confidence Interval \r\n","\r\n","Confidence Interval is the range of values we are fairly confident the true value lies in\r\n","\r\n","ie: An interval that covers 95% of the means \r\n","\r\n","\r\n","The $100(1-\\alpha)\\%$ confidence interval is \r\n","\r\n","$$ \\bar{x} \\pm  t_{1-\\alpha/2, n-1} \\dfrac{\\hat{\\sigma}}{\\sqrt{n}} $$\r\n","\r\n","\r\n","```python\r\n","# Imports\r\n","from scipy.stats import t\r\n","\r\n","# Function\r\n","def confidence_interval(data):\r\n","\r\n","    estimated_mean = np.mean(data)\r\n","\r\n","    # Confidence Interval = 0.95% in this case\r\n","    offset = t.ppf( (1 + 0.95)/2, df=len(data)-1) * sem(data)\r\n","    bounds = [estimated_mean - offset, estimated_mean + offset]\r\n","\r\n","    return estimated_mean, bounds\r\n","    \r\n","```\r\n","\r\n","### Bootstraping\r\n","\r\n","Bootstrapping is any test or metric that uses random sampling with replacement, and falls under the broader class of resampling methods. \r\n","\r\n","This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods.\r\n","\r\n","Bootstraping always gives a normal distrubtion of means\r\n","\r\n","```python\r\n","\r\n","# Write a Bootstrap function that records the fitted models \r\n","def BootstrapCoef(data,numboot=1000):\r\n","    regr = sklearn.linear_model.LinearRegression()\r\n","    #numboot = 1000\r\n","    n = len(data)\r\n","    theta = np.zeros((numboot,2))    \r\n","    for i in range(numboot):\r\n","        # Sample Data\r\n","        d = data.sample(n, replace=True)\r\n","\r\n","        X_fit = np.c_[d.ht]\r\n","\r\n","        # Fit Data using Linear Regression\r\n","        regr.fit(X_fit,d.wt)\r\n","\r\n","        # Store Model Paramaters\r\n","        theta[i,0]=regr.intercept_\r\n","        theta[i,1]=regr.coef_\r\n","    return theta\r\n","\r\n","params = BootstrapCoef(df,100)\r\n","\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"Z-xUdcfiWmCm"},"source":["# **LAB 5**\r\n","\r\n","### **Cross Validation**\r\n","\r\n","Cross validation spilts the data int blocks. One block of data is kept for testing and the rest are used for training. Cross validation then cycles through each block assigning it to the testing data and the rest of the blocks to training data. Then is takes the average score of each training - testing set at the end. \r\n","\r\n","Training Data:\r\n","Is used to estimate the paramters for the machine learning methods\r\n","\r\n","Testing Data:\r\n","Used to evaluate how well the machine learning method works\r\n","\r\n","Cross Validation Size:\r\n","\r\n","Lower = better\r\n","\r\n","| Paramteter| 2 Folds | 5-10 Folds | N Folds |\r\n","|-|-|-|-|\r\n","|Overestimation bias of prediction error| Bad | Present | Nearly Unbiased |\r\n","|Computational Cost | Low | Mid | High | \r\n","|Variance of estimate| Low | Low | High |\r\n","\r\n","\r\n","### Cross Validation Score\r\n","\r\n","```python\r\n","# CV is Fold Cross Validation\r\n","cv_score = cross_val_score(model2, Xtrain, ytrain, cv = 5, scoring=make_scorer(mae))\r\n","print(cv_score.mean())\r\n","```\r\n","\r\n","\r\n","### **Effective Test Size**\r\n","\r\n","Using the formula for the effective test size ($n$) to get the precision to specific precision ($d$) relative to the test loss standard deviation of $\\sigma_l$\r\n","$$ n = \\left(\\frac{1.96 \\sigma_l}{d}\\right)^2$$\r\n","\r\n","```python\r\n","\r\n","def mae(y,ypred):\r\n","    return abs(y - ypred).mean()\r\n","\r\n","mu = mae(model_data.overall,model_data.overall.median())\r\n","loss = abs(model_data.overall - model_data.overall.median())  \r\n","sigma = loss.std()\r\n","\r\n","# Test Size\r\n","test_size = (2*sigma/d)**2\r\n","```\r\n","\r\n","\r\n","\r\n","### **Linear Regression**\r\n","\r\n","```python\r\n","model1 = Pipeline([\r\n","    ('linear_regression', LinearRegression())\r\n","])\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"cL6Tosiw3Uo7"},"source":["# **LAB 6**\r\n","\r\n","#### **Standarization**\r\n","\r\n","The standardize function centers the data around x = 0. This is because the Standard Scaler function coverts the data to z-scores. Z-scores are a measure if how of many standard deviations the data point is from the mean. The majority (68%) of the data will lie within 1 standard deviation or a z score between (+1, -1). Standardizing the data allows for easy comparision between different features\r\n","\r\n","```python \r\n","\r\n","# Example Pipeline\r\n","model_pipeline = Pipeline([\r\n","    # Standardization\r\n","    ('standardize', StandardScaler()),\r\n","    # Linear Regression\r\n","    ('reg', sk.linear_model.LinearRegression())\r\n","])\r\n","\r\n","# Access Step inside Pipeline\r\n","standardizer_step = model_pipeline.named_steps['standardize']\r\n","transformed_X = standardizer_step.fit_transform(Xtrain)\r\n","```\r\n","\r\n","\r\n","### **Ridge Regression (L2):**\r\n","\r\n","Ridge regression = Sum of Square Residuals + $\\lambda \\times slope^2$\r\n","\r\n","$$ Ridge = \\sum_{i=1}^N residuals^2 + Pentalty \\times Slope^2 $$\r\n","$$ Ridge = \\sum_{i=1}^N( y_a(i) - \\beta x(i))^2 + \\lambda \\beta^2 $$\r\n","\r\n","Ridge regression adds a pentaly function on the slope\r\n","Pentaly can be anywhere betweem 0 and inf\r\n","\r\n","Ridge regression introduces bias in the model to potentially reduce variance of the testing data. By have a slighty worse fit of the tr aining data (when it is limited) Ridge Regression can provide better long term preductions of the testing data. Ridge regression makes preidiction less sensetive to changes in the input variable means a smaller change in the output variable.\r\n","\r\n","\r\n","\r\n","Lest Square needs 4 points to estimate parameters. Ridge regression can be used to estimate all parameters with less data points. Eg 1000 parameters with only 500 data points or less. \r\n","\r\n","**Note:** Ridge Regression can shrink slope asymptotically close to 0\r\n","Ridge Regression is better when most model features are useful\r\n","\r\n","```python\r\n","ridge_pipeline = Pipeline([('poly_features', PolynomialFeatures()),\r\n","                           ('scaler', StandardScaler()), \r\n","                           ('ridge_regression', Ridge(alpha=np.exp(2)))])\r\n","\r\n","ridge_pipeline.fit(x_train, y_train)\r\n","yp_ridge = ridge_pipeline.predict(x_test)\r\n","```\r\n","\r\n","### Ridge - Getting Best Lambda\r\n","\r\n","```python\r\n","params = {'reg__alpha': np.exp(np.linspace(-8,6,15))}\r\n","\r\n","# Grid search lets you test multiple paramters for lambda \r\n","gscv = GridSearchCV(pipeline, param_grid=params, cv=10, scoring = 'neg_mean_squared_error', refit=True)\r\n","gscv.fit(X_new_train, ytrain)\r\n","\r\n","# Alternatively \r\n","# The best lambda can be found using gscv.best_params_\r\n","\r\n","results = pd.DataFrame(gscv.cv_results_)\r\n","plt.scatter( np.linspace(-8, 6,15), -results.mean_test_score)\r\n","plt.xlabel(r'$\\log(\\lambda)$')\r\n","```\r\n","\r\n","### **Lasso Regression (L1):**\r\n","\r\n","Lasso regression adds a pentaly function on the slope\r\n","\r\n","Lasso regression = Sum of Square Residuals + $\\lambda \\times |Slope|$\r\n","$$ Ridge = \\sum_{i=1}^N residuals^2 + Pentalty \\times |Slope| $$\r\n","$$ Ridge = \\sum_{i=1}^N( y_a(i) - \\beta x(i))^2 + \\lambda |\\beta| $$\r\n","\r\n","Lasso regression can shrink slope to 0\r\n","Lasso regression is better when most model features are useless since they can be discluded from the line of best fit. This has the potential to simpifly a model greatly. This makes it better than ridge regression at reducing variance. \r\n","\r\n","```python\r\n","lasso_pipeline = Pipeline([('poly_features', PolynomialFeatures()), \r\n","                           ('scaler', StandardScaler()), \r\n","                           ('lasso', sk.linear_model.Lasso(alpha=np.exp(2)))])\r\n","\r\n","lasso_pipeline.fit(x_train, y_train)\r\n","```\r\n","\r\n","### **Elastic Net Regression:**\r\n","\r\n","Elastic Net Regression combines the strength of Lasso and Ridge Regression\r\n","\r\n","$$ Elastic = \\sum_{i=1}^N residuals^2 + Pentalty_L \\times |Slope|+ Pentalty_R \\times Slope^2 $$\r\n","$$ Elastic = \\sum_{i=1}^N( y_a(i) - \\beta x(i))^2 + \\lambda_L |\\beta| + \\lambda_R \\beta^2 $$\r\n","\r\n","Ridge Regression shrinks all of the parameters for the correlated variable together \r\n","\r\n","Lasso Regression picks one of the correlated terms and eliminates the other terms\r\n","\r\n","Elastic Net regression groups and shrinks the paramteres associated with the correlated variables and leaves them in equation or removes them all at once. \r\n","\r\n","\r\n","### Plot Slope of Each Parameter Ridge Regression\r\n","\r\n","```python\r\n","regularization_strength = np.exp(np.linspace(np.log(0.2),np.log(200),50))\r\n","\r\n","coefs = np.zeros((regularization_strength.size, X.shape[1]))\r\n","\r\n","for i,L in enumerate(regularization_strength):\r\n","    lasso_pipe = Pipeline([\r\n","    ('scale', StandardScaler()),\r\n","    ('linear_regression', Lasso(alpha=L, \r\n","                                               fit_intercept=True)) \r\n","    ])\r\n","    \r\n","    lasso_pipe.fit(Xtrain, ytrain)\r\n","    coefs[i] = lasso_pipe.named_steps['linear_regression'].coef_    \r\n","\r\n","fig, ax = plt.subplots(dpi = 120)\r\n","ax.plot(np.log(regularization_strength), coefs)\r\n","ax.set_xlabel(r'$\\log(\\lambda)$', fontsize = 16)\r\n","ax.set_ylabel(r'$\\hat{\\beta}$', fontsize = 16)\r\n","ax.set_title('Coefficient Path', fontsize = 18)\r\n","ax.set_xlim(-4,None)\r\n","\r\n","for i, name in enumerate(DfFeatures.columns[:-1]):\r\n","    \r\n","    ax.annotate(name, xy = (-3, coefs[0,i]), ha = 'left', fontsize = 8)\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"33EAJ01NWxeC"},"source":["# **LAB 8**\r\n","\r\n","### **Random Forest**\r\n","\r\n","* Step 1: Bootstrap Data Set  (Random Replace)\r\n","* Step 2: Create a Tree\r\n","* Step 3: Repeat n number of times\r\n","* Now we have a random Forest\r\n","\r\n","Testing new Data\r\n","\r\n","When we get new data we run it through all the random forests created in the last step. At each tree we record the result. Looking at the overall count we can then determine the classification of the data\r\n","\r\n","Bagging:\r\n","\r\n","Bootstrapping Data plus using the aggregate of the data\r\n","\r\n","Out of Bag Data Set:\r\n","\r\n","Data that didnot end up in the bootstrapped data set. We use this to test if the random forest properly classifies the data. Out of Bag Error is the portion of out of bag samples incorrectly classified\r\n","\r\n","```python\r\n","    num_trees = 500\r\n","    # Bagged decision tree \r\n","    tree1 = DecisionTreeClassifier()\r\n","    model_1 = BaggingClassifier(base_estimator = tree1, n_estimators = num_trees, random_state = seed)\r\n","    model_1.fit(Xtrain, ytrain)\r\n","    y_p1 = model_1.predict(Xtest)\r\n","    bag_accuracy = accuracy_score(ytest, y_p1)\r\n","    \r\n","    # Random Forest (max_features = 1)\r\n","    model_2 = RandomForestClassifier(max_features = 1, random_state = seed)\r\n","    model_2 = model_2.fit(Xtrain, ytrain)\r\n","    y_p2 = model_2.predict(Xtest)\r\n","    rf_mf1_accuracy = accuracy_score(ytest, y_p2)\r\n","```\r\n","\r\n","### **Ada Boost**\r\n","\r\n","In a forest of trees made with Ada Boost trees are usually just one node with and two leaves. One use one variable to make a decision so they are weak learners. In a forest of trees with Ada Boost some trees decisions have more weight to them in regards to the final classification. Each stump is made by take the previous stump's error into account.\r\n","\r\n","\r\n","\r\n","*   Step 1: Evalute all tree and determine which tree best represents the data\r\n","*   Step 2: Reweight the data\r\n","*   Normalize Weight\r\n","*   Selected the next best stump \r\n","*   Bootstrap new data using weights as probabilities \r\n","*   Set weights equal again\r\n","*   Repeat\r\n","\r\n","Weight of Stump\r\n","$$ Amount of Say = \\frac{1}{2} log\\left(\\frac{1 - Total Error}{TotalError}\\right)$$\r\n","\r\n","$$ New Sample Weight = Sample Weight \\times e^{Amount Of Say} $$\r\n","\r\n","### **Graident Boost**\r\n","\r\n","* Build bigger fixed sized trees than AdaBoost\r\n","* Gradient boost scales all tree by the same value\r\n"]},{"cell_type":"markdown","metadata":{"id":"5uxeI5m9aXut"},"source":["# **LAB 9**\r\n","\r\n","### **Neural Networks**\r\n","\r\n","Neural Networks can fit a squiggle to data\r\n","\r\n","Hidden Layers:\r\n","\r\n","Number of Layers between the input and output nodes\r\n","\r\n","### Activation Functions\r\n","https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0\r\n","https://pytorch.org/docs/stable/nn.html#linear-layers\r\n","\r\n","\r\n","### Back propagation\r\n","\r\n","*  Use chain rules to find derivative of the Sum of Squared Residuals (SSR)\r\n","*  Use gradient descent to optimize the unkown paramter\r\n","\r\n","\r\n","### Graphing\r\n","\r\n","```python\r\n","def live_plot(loss, train_acc, valid_acc=None, figsize=(7,5), title=''):\r\n","    clear_output(wait=True)\r\n","    fig, ax1 = plt.subplots(figsize=figsize)\r\n","    ax1.plot(loss, label='Training Loss', color='red')\r\n","    ax1.legend(loc='lower left')\r\n","    ax1.set_ylabel('Cross Entropy Loss')\r\n","    ax2 = ax1.twinx()\r\n","    ax2.plot(train_acc, label='Training Accuracy', color='green')\r\n","    if valid_acc is not None:\r\n","        ax2.plot(valid_acc, label='Validation Accuracy', color='blue')\r\n","    ax2.legend(loc='lower right')\r\n","    ax2.set_ylabel('Accuracy (%)')\r\n","    ax2.set_xlabel('Epoch')\r\n","    plt.title(title)\r\n","    plt.show()\r\n","\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"iBzxUHMDaq1a"},"source":["# **LAB 10**\r\n","\r\n","### **Clustering**\r\n","\r\n","### **PCA | Princal Component Analysis**\r\n","\r\n","PCA tells you which variable is most important in representing the variation in the output data\r\n","\r\n","To test how well a line fits the data PCA projects the data on it. PCA either minimzes the distance to the line (residuals) or maximize the distance from the projected point to the origin (variance)\r\n","\r\n","PCA is a linear combination of variables. Sort of like a recipe. PCA is in n eigen vector. And the proportion of the variables are called loading scores.\r\n","\r\n","PCA 2 is the line prependicular to PCA 1\r\n","\r\n","Next the variation of each PCA can be calculated. \r\n","\r\n","$$Variance PCA = \\frac{Sum Of Squares(PC1)}{n-1} $$\r\n","\r\n","$$ New Sample Weight = Sample Weight \\times e^{Amount Of Say} $$\r\n","\r\n","Scree Plot is a graphical representation of the percentages of variation that each PC accounts for"]},{"cell_type":"markdown","metadata":{"id":"SdUvAPG0GsMo"},"source":["### K Nearest Neighbor\r\n","\r\n","K nearest Neighbor looks at the classification of the closest data points (K). \r\n","Ideally keep K odd to avoid ties\r\n","\r\n","\r\n","### K Means Clustering \r\n","\r\n","* Step 1 select the number of clusters\r\n","* Step 2 Select 3 disctinct data points \r\n","* Step 3 Measure the distance form each point\r\n","* Step 4 Assign the nearest data point to their repsective cluster\r\n","\r\n","* Step 5 Move cluster locations and Repeat\r\n","\r\n","To determine how well the clustering works, add up the total variation within each cluster. The best model is the one that minimzes this.\r\n","\r\n","K means clustering specifically tries to put the data into the number of clusters you tell it to.\r\n","\r\n","How to determine K?\r\n","Compare the total variation of the models (k, k+1). Graph these results. Where the variation drops off is where the optimal value of k should be.\r\n","\r\n","Move \r\n","\r\n","### Hierarchical Clustering\r\n","\r\n","Tell the user which points are most similar pairwise"]}]}