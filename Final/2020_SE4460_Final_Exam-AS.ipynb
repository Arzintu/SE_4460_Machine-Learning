{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "name": "2020-SE4460-Final-Exam.ipynb",
   "provenance": []
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKtZKpMOcm9f"
   },
   "source": [
    "# Final Exam\n",
    "### YourUserID: 250804239\n",
    "\n",
    "## General\n",
    "The instructions for the final exam are included in the cover page share on OWL. In addion, some basic rules:\n",
    "\n",
    "* You **are allowed** to use any document and source on your computer and look up documents on the internet.\n",
    "* You or **not allowed** to share documents, or communicate in any other way with people about the final during the final. Afterwards, you are not allowed to share the final, or talk about its content, with students who still have to take a make-up final  \n",
    "* Most questions also require a written answer. The answer to these questions should be given in full English sentences.\n",
    "* All Figures should have a x- and y-axis label.\n",
    "* The Final exam needs to be submitted on OWL  before the deadline. If you have accomodation officially approved by student counseling, you may have extra time.  \n",
    "\n",
    "### Additional Guidance\n",
    "\n",
    "If at any point you are asking yourself \"are we supposed to...\", then *write your assumptions clearly in your exam and proceed according to those assumptions.*\n",
    "\n",
    "Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcuYw0aFcm9u"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VQmK44mcm9u"
   },
   "source": [
    "## Data set \n",
    "World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk. \n",
    "\n",
    "### Source\n",
    "The dataset (framingham.csv) is publically available on the Kaggle website, and it is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient went on to develop coronary heart disease (CHD) in a 10 year period. The dataset provides the patientsâ€™ information. It includes over 4,000 records and 15 attributes.\n",
    "\n",
    "### Variables\n",
    "Each attribute is a potential risk factor. There are both demographic, behavioral and medical risk factors.\n",
    "\n",
    "* male: Indicator variable for biological sex (1:male 0:female)\n",
    "* age: Age of the patient in years \n",
    "* education: Education level. Ordinal variable.c\n",
    "* currentSmoker: whether or not the patient is a current smoker (1:yes 0:no)\n",
    "* cigsPerDay: the number of cigarettes that the person smoked on average in one day\n",
    "* BPMeds: whether or not the patient was on blood pressure medication (1:yes 0:no)\n",
    "* prevalentStroke: whether or not the patient had previously had a stroke \n",
    "* prevalentHyp: whether or not the patient was hypertensive\n",
    "* diabetes: whether or not the patient had diabetes\n",
    "* totChol: total cholesterol level\n",
    "* sysBP: systolic blood pressure\n",
    "* diaBP: diastolic blood pressure\n",
    "* BMI: Body Mass Index\n",
    "* heartRate: heart rate (beats per minute)\n",
    "* glucose: glucose level\n",
    "* TenYearCHD: 10 year risk of coronary heart disease (1: developed signs of CHD in 10 year period, 0: did not develop CHD) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VwrgtY80cm9v",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## perform the necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import t, sem\n",
    "\n",
    "from sklearn.metrics import log_loss, make_scorer, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import l1_min_c\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from IPython.display import clear_output\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-ZQz2IMcm9w"
   },
   "source": [
    "## Task 1: Logistic regression (29pts)\n",
    "### Question 1 (2pt)\n",
    "Load the Data set framingham.csv *discarding all rows in the data frame that include any NaNs*. \n",
    "\n",
    "Split the data into equals-sized training and test sets (using a random_state = 0). \n",
    "\n",
    "How many observations do you have in your training set?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s3audaXgcm9w",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "model_data = pd.read_csv('framingham.csv')\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "y_data = model_data.TenYearCHD.values\n",
    "x_data = model_data.drop(columns=[\"TenYearCHD\"]).values\n",
    "test_size = 0.5\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = test_size, random_state = 0)\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7a6e8654b076>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'framingham.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTenYearCHD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TenYearCHD\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\documents\\jupyter\\venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\documents\\jupyter\\venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\documents\\jupyter\\venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\documents\\jupyter\\venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\documents\\jupyter\\venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'framingham.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'framingham.csv'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhbPiWO9cm9w"
   },
   "source": [
    "### Question 2  (6pts)\n",
    "What is the baseline rate (mean) of the 10-year risk of CHD in the test sample? \n",
    "\n",
    "What is the baseline performance for the following evaluation criteria - i.e. the expected test performance of a classifier that always predicts 0? \n",
    "\n",
    "* Accuracy\n",
    "* F1-score\n",
    "* Specificity \n",
    "* Sensitivity\n",
    "* Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iIsbdKJ6cm9w",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Framingham, Massachusetts\n",
    "# classification_report(y_test, 0 )\n",
    "\n",
    "def compute_performance(yhat, y, classes):\n",
    "    \n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
    "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
    "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
    "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision\n",
    "    # \"Of the ones I labeled +, how many are actually +?\"\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # Recall\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    recall = tp / (tp + fn)    \n",
    "    \n",
    "    # Sensitivity\n",
    "    # \"Of all the + in the data, how many do I correctly label?\"\n",
    "    sensitivity = recall\n",
    "    \n",
    "    # Specificity\n",
    "    # \"Of all the - in the data, how many do I correctly label?\"\n",
    "    specificity = tn / (fp + tn)\n",
    "    \n",
    "    # Print results\n",
    "    \n",
    "    print(\"Accuracy:\",round(acc,3),\"Recall:\",round(recall,3),\"Precision:\",round(precision,3),\n",
    "          \"Sensitivity:\",round(sensitivity,3),\"Specificity:\",round(specificity,3))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXQn3J1dcm9x"
   },
   "source": [
    "### Question 3 (8pts)\n",
    "Using the training data, build a Logisitic regression model (without regularization) based on the demographic variables (male, age, education) only. Using 10-fold cross-validation on the training set, report the performance of this model using a suitable evaluation (scoring) criterion. \n",
    "<br>__Written answer__: Justify your choice of evaluation criterion. Mention at least 2 other evaluation criteria and explain why these are not suitable, or not as good. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Log Loss was used for the scoring because it has a good trade off between recall and precision\n",
    "\n",
    "MSE - is built for linear regresion \n",
    "Precision - You cn get 100% precision by always choosing zero \n",
    "Recall - Same logic as precision \n",
    "\n",
    "Basically these two don't provide a good trade off \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DOsVxQkxcm9x",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "lr = LogisticRegression(penalty = 'none',max_iter=10000)\n",
    "cv_score = cross_val_score(lr, x_train[:,0:3], y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "\n",
    "print(cv_score)\n",
    "print(cv_score.mean())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfhZqtWEcm9x"
   },
   "source": [
    "\n",
    "### Question 4 (6pts)\n",
    "By dropping one variable at a time from the model from Question 3, determine which of the 3 variables is the most crucial variable in the predictive model. Which variable could most likely be excluded? "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A0MXp7iwcm9x",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Age \n",
    "\n",
    "cv_score_1 = cross_val_score(lr, x_train[:,0:1], y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "cv_score_2 = cross_val_score(lr, x_train[:,0:2:2], y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "cv_score_3 = cross_val_score(lr, x_train[:,1:2], y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "\n",
    "print(cv_score_1.mean())\n",
    "print(cv_score_2.mean())\n",
    "print(cv_score_3.mean())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TKHqw-Scm9y"
   },
   "source": [
    "### Question 5 (7pts)\n",
    "Combine all variables (except the one you want to predict!) into a Logistic regression model without regularization. Using the training set only, determine the average cross-validated log likelihood of the model on the training data, using 10-fold crossvalidation. \n",
    "\n",
    "__Hint__: The log-likelihood for a single observation $y$ and a predicted probability $\\hat{y}$ is \n",
    "$ log P(y|\\hat{y})= y log(\\hat{y}) + (1-y) log(1-\\hat{y})$. There is a sklearn scoring method that calculates this quantity:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "428m_43mcm9y",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "lr = LogisticRegression(penalty = 'none',max_iter=10000)\n",
    "cv_score_all = cross_val_score(lr, x_train, y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "print(cv_score_all.mean())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4irU05lZcm9y"
   },
   "source": [
    "## Task 2: Regularized Logisitic regression model (27pts) \n",
    "\n",
    "### Question 1 (8pts)\n",
    "Use L1 regularization to determine the best set of variables to include in a predictive model.\n",
    "Add a penalty of $\\lambda \\sum_{i}{|\\beta_i|_1}$ ($\\beta_i$ are your regression coefficients) to the Logistic regression model. Vary the regularization parameter $\\lambda$ between 0.2 and 200, evenly spaced in log-space. \n",
    "\n",
    "Apply all necessary preprocessing steps to your variables to be able to compare meanfully  between different predictors in the model. \n",
    "\n",
    "Plot the coefficient path, i.e., the size of the regression coefficients relative to the size of the the regularization paramter. \n",
    "<br>__Written Answer :__ Which two variables are the two most important predictors of 10-year risk of CHD?   "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aeIUmC07cm9y",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# model 3 - linear regression scaling and polynomial features\n",
    "    \n",
    "model_pipeline = Pipeline([\n",
    "            ('Scaler', StandardScaler()),\n",
    "\n",
    "            ('Logistic', LogisticRegression(penalty = 'l1', solver='liblinear', max_iter=10000)),\n",
    "            ])\n",
    "    \n",
    "coefs_ = []\n",
    "\n",
    "r_min = 0.2\n",
    "r_max = 200\n",
    "r_count = 50\n",
    "cs = np.exp(np.linspace(np.log(r_min),np.log(r_max),r_count))\n",
    "\n",
    "    \n",
    "# From scikit website\n",
    "for c in cs:\n",
    "    model_pipeline.named_steps['Logistic'].set_params(C=c)\n",
    "    model_pipeline.fit(x_train, y_train)\n",
    "    coefs_.append(model_pipeline.named_steps['Logistic'].coef_.ravel().copy())\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(dpi = 120)\n",
    "\n",
    "coefs_ = np.array(coefs_)\n",
    "name_data = model_data.drop(columns=[\"TenYearCHD\"])\n",
    "\n",
    "ax.plot(np.log(cs), coefs_, marker='o')\n",
    "print(cs)\n",
    "print(np.log(cs))\n",
    "ax.set_xlabel('log(C)')\n",
    "ax.set_ylabel('Coefficients')\n",
    "ax.set_title('Logistic Regression Path')\n",
    "ax.axis('tight')\n",
    "\n",
    "\n",
    "ax.set_xlim(None, 8)\n",
    "for i, name in enumerate(name_data.columns):\n",
    "    print(name)\n",
    "    ax.annotate(name, xy = (6, coefs_[-1,i]), ha = 'left', fontsize = 8) \n",
    "    \n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF6GDBtgcm9z"
   },
   "source": [
    "### Question 2 (7pts)\n",
    "Using the same model and the range of regularisation parameters as in T2, Q1, determine the 10-fold crossvalidated performance for different values of the L1-regularisation parameter. Use the cross-validated log-likelihood of the data under the model as evaluation criterion. (If you couldn't calulcate the log-likelihood in Task 1, Question 5, use another suitable evaluation criterion).   \n",
    "\n",
    "Make a plot of the crossvalidated log-likelihood against $log(\\lambda)$. \n",
    "\n",
    "<br>__Written Answer :__ Base on this criterion, what is the optional setting of the L1-regularization parameter? At this value, which variables contribute to the prediction? \n",
    "\n",
    "The best lambda is 0.7373144702031299"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9qInGZbrcm9z",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "cv_scores = []\n",
    "r_min = 0.2\n",
    "r_max = 200\n",
    "r_count = 100\n",
    "cs = np.exp(np.linspace(np.log(r_min),np.log(r_max),r_count))\n",
    "for c in cs:\n",
    "    model_pipeline = Pipeline([\n",
    "            ('Scaler', StandardScaler()),\n",
    "\n",
    "            ('Logistic', LogisticRegression(penalty = 'l1', solver='liblinear', max_iter=10000)),\n",
    "            ])\n",
    "    model_pipeline.named_steps['Logistic'].set_params(C=c)\n",
    "    cv_score = cross_val_score(model_pipeline, x_train, y_train, cv = 10, scoring=make_scorer(log_loss))\n",
    "    cv_scores.append(cv_score.mean())\n",
    "\n",
    "print(cv_scores)\n",
    "print(cs)\n",
    "plt.plot(np.log(cs), cv_scores, marker='o')\n",
    "\n",
    "best_lambda = cs[np.argmin(cv_scores)]\n",
    "print(best_lambda)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2YVV76Kcm9z"
   },
   "source": [
    "### Question 3 (6pts)\n",
    "Using the best lambda that you found, fit the L1-regularized model to all the training data and then get the the predicted probability for each item of the test set. \n",
    "\n",
    "Plot the ROC curve for the test set and model.\n",
    "\n",
    "Report the area under the ROC curve. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MoGj-4Rlcm9z",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "best_lambda = cs[np.argmin(cv_scores)]\n",
    "print(best_lambda)\n",
    "\n",
    "# ROC for Amount-only classifier\n",
    "model_pipeline = Pipeline([\n",
    "            ('Scaler', StandardScaler()),\n",
    "            ('Logistic', LogisticRegression(penalty = 'l1', solver='liblinear', max_iter=10000)),\n",
    "            ])\n",
    "\n",
    "model_pipeline.named_steps['Logistic'].set_params(C=best_lambda)\n",
    "model_pipeline.fit(x_train, y_train)\n",
    "\n",
    "ytest_prob_amount = model_pipeline.predict_proba(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, ytest_prob_amount[:,1], pos_label=1)\n",
    "ax=sns.lineplot(fpr,tpr)\n",
    "ax.set(xlabel=\"False Positive Rate\",ylabel=\"True Positive Rate\")\n",
    "auc(fpr,tpr)\n",
    "\n",
    "print(thresholds)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MLk-axkcm9z"
   },
   "source": [
    "### Question 4 (6pts)\n",
    "Given the resulting ROC-curve, if you wanted your predictive model to have a sensitivity of more than 0.8, what is the best specificity you could achieve on the test set? \n",
    "\n",
    "Provide the 95% confidence interval on the specificity. Note that there are different ways of getting a valid confidence interval, including the normal approximation (central limit theorem) to the binomial distribution or bootstrap (see Labs for hints). "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To have a sensitivity of more than 80% of people with coronary heart disease the best specificity would be \n",
    " \n",
    " would \n",
    "require a precision score of over 0.60. The amount only classifier does not have this level of precision which is why the all values classifier should be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Z3Iv5YXcm90",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def confidence_interval(data):\n",
    " \n",
    "    estimated_mean = np.mean(data)\n",
    " \n",
    "    # Confidence Interval = 0.95% in this case\n",
    "    offset = t.ppf( (1 + 0.95)/2, df=len(data)-1) * sem(data)\n",
    "    bounds = [estimated_mean - offset, estimated_mean + offset]\n",
    " \n",
    "    return estimated_mean, bounds\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov-yeiUjcm90"
   },
   "source": [
    "## Task 3: Deep learning (26pts + 4 Bonus points)\n",
    "In this task we are looking to see if we can beat the best logistic regression model, using \"deep\" learning. __Only the PyTorch package is to be used in this exam. Using other Deep learning libraries is not permitted.__ \n",
    "\n",
    "### Question 1 (7 pts)\n",
    "Build a simple linear model with 15 input units for the 15 predictor variables in the CHD data set and two output units for the two output classes (0: no CHD risk, 1: CHD risk). Use a LogSigmoid as your output non-linearity. \n",
    "\n",
    "Use the training data set (task 1, Question 1) to train the network:\n",
    "* Z-standarize your input variables \n",
    "* Use the Cross-entropy loss as a training criterion (same as for logisitic regression) \n",
    "* Use Stochastic gradient descent optimizer with a learning rate of 0.01\n",
    "* Run the optimization for 10000 iterations and record the loss for each iteration \n",
    "* Make a plot of iterations vs. loss "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vWyn8tpzcm90",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def cross_entropy(input, target):\n",
    "    max_val, index = target.max(dim=1)\n",
    "    return nn.CrossEntropyLoss()(input, index)\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 10000\n",
    "\n",
    "#Define model \n",
    "linear_neural_net = nn.Sequential(\n",
    "    nn.Linear(x_train.shape[1], x_train.shape[1]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(x_train.shape[1], x_train.shape[1]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(x_train.shape[1], 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "transformer = StandardScaler()\n",
    "transformer = transformer.fit(x_train, y_train)\n",
    "\n",
    "# Define loss function \n",
    "loss_fn = cross_entropy\n",
    "\n",
    "x_train_tranform = transformer.transform(x_train)\n",
    "x_test_tranform = transformer.transform(x_test)\n",
    "\n",
    "#Convert dataset to tensors for Test\n",
    "x_train_tensor = torch.from_numpy(x_train_tranform.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(np.concatenate([y_train.astype(np.longlong).reshape(-1,1), (1-y_train).astype(np.longlong).reshape(-1,1)], axis=1))\n",
    "\n",
    "#Convert dataset to tensors for Train\n",
    "x_test_tensor = torch.from_numpy(x_test_tranform.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(np.concatenate([y_test.astype(np.longlong).reshape(-1,1), (1-y_test).astype(np.longlong).reshape(-1,1)], axis=1))\n",
    "loss_list = []\n",
    "\n",
    "# Train model \n",
    "for i in range (iterations):\n",
    "    yp = linear_neural_net(x_train_tensor)\n",
    "    loss = loss_fn(yp, y_train_tensor)\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "          print(i, loss.item())\n",
    "            \n",
    "    linear_neural_net.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "          for param in linear_neural_net.parameters():\n",
    "                param -= learning_rate * param.grad \n",
    "\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "ax.plot(np.linspace(1,iterations,iterations), loss_list)\n",
    "ax.set(xlabel=\"Iterations\",ylabel=\"Loss\", title= 'Loss vs Iterations')\n",
    "\n",
    "\n",
    "\n",
    " "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Oi_2E4Rcm91"
   },
   "source": [
    "### Question 2 (8pts)\n",
    "Use the trained network to make a prediction for the test set. Report an area under the ROC curve for the test data set. \n",
    "\n",
    "HINT: To obtain a probability from the output of the network, take the logistic function of the difference between the activities of the two output units. Remember the output unit 0 is high when the model \"thinks\" is class is 0 and the output unit 1 is higher when the model \"thinks\" the class is 1.   "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a9oGbFQKcm91",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "y_pred = linear_neural_net(x_test_tensor)\n",
    "y_pred_prob = y_pred.detach().numpy()[:,1] - y_pred.detach().numpy()[:,0]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_tensor.detach().numpy()[:,1], y_pred_prob, pos_label=1)\n",
    "ax=sns.lineplot(fpr,tpr)\n",
    "\n",
    "ax.set(xlabel=\"False Positive Rate\",ylabel=\"True Positive Rate\", title= 'False Positive Rate vs True Positive Rate')\n",
    "\n",
    "print(\"ROC Area\")\n",
    "auc(fpr,tpr)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbAOhTVCcm91"
   },
   "source": [
    "### Question 3 (6pts)\n",
    "Now add a hidden layer with 50 units into the network. Use a LogSigmoid non-linearity for the hidden layer. Leave all the other parameters the same as for Question 1. Again, plot the loss as a function of the iteration. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oPt6s2RBcm91",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def cross_entropy(input, target):\n",
    "    max_val, index = target.max(dim=1)\n",
    "    return nn.CrossEntropyLoss()(input, index)\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 10000\n",
    "\n",
    "#Define model \n",
    "hidden_neural_net = nn.Sequential(\n",
    "    nn.Linear(x_train.shape[1], x_train.shape[1]),\n",
    "    nn.LogSigmoid(),\n",
    "    nn.Linear(x_train.shape[1], 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "transformer = StandardScaler()\n",
    "transformer = transformer.fit(x_train, y_train)\n",
    "\n",
    "# Define loss function \n",
    "loss_fn = cross_entropy\n",
    "\n",
    "x_train_tranform = transformer.transform(x_train)\n",
    "x_test_tranform = transformer.transform(x_test)\n",
    "\n",
    "#Convert dataset to tensors for Test\n",
    "x_train_tensor = torch.from_numpy(x_train_tranform.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(np.concatenate([y_train.astype(np.longlong).reshape(-1,1), (1-y_train).astype(np.longlong).reshape(-1,1)], axis=1))\n",
    "\n",
    "#Convert dataset to tensors for Train\n",
    "x_test_tensor = torch.from_numpy(x_test_tranform.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(np.concatenate([y_test.astype(np.longlong).reshape(-1,1), (1-y_test).astype(np.longlong).reshape(-1,1)], axis=1))\n",
    "loss_list = []\n",
    "\n",
    "# Train model \n",
    "for i in range (iterations):\n",
    "    yp = hidden_neural_net(x_train_tensor)\n",
    "    loss = loss_fn(yp, y_train_tensor)\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "          print(i, loss.item())\n",
    "            \n",
    "    hidden_neural_net.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "          for param in hidden_neural_net.parameters():\n",
    "                param -= learning_rate * param.grad \n",
    "\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "ax.plot(np.linspace(1,iterations,iterations), loss_list)\n",
    "ax.set(xlabel=\"Iterations\",ylabel=\"Loss\", title= 'Loss vs Iterations')\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXkxUyDmcm92"
   },
   "source": [
    "### Question 4 (5pts)\n",
    "As for Question 2, report the area under the ROC curve for this network on the test set. \n",
    "\n",
    "__Written answer:__ What do you conclude? "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfornately my neural network than logistic model. I probably messed something up or misunderstood something in the question.\n",
    "The performance of the models can be compared using the auc vaules of the roc curves. \n",
    "\n",
    "The hidden network performed the worst out of all of them  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B9YWZejDcm92",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "y_pred = hidden_neural_net(x_test_tensor)\n",
    "y_pred_prob = y_pred.detach().numpy()[:,1] - y_pred.detach().numpy()[:,0]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_tensor.detach().numpy()[:,1], y_pred_prob, pos_label=1)\n",
    "ax=sns.lineplot(fpr,tpr)\n",
    "\n",
    "ax.set(xlabel=\"False Positive Rate\",ylabel=\"True Positive Rate\", title= 'False Positive Rate vs True Positive Rate')\n",
    "\n",
    "print(\"ROC Area\")\n",
    "auc(fpr,tpr)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93YtU3w5cm92"
   },
   "source": [
    "### Question 4  -  Hyperparameter Tuning (4 Bonus pts)\n",
    "Good Job, your employers are very impressed with your progress! Despite their satisfaction, you decide to try and improve your models further using hyperparameter optimization. You decide to test only a few hyperparameter combinations.\n",
    "\n",
    "Create a a function to performa the hyperparameter tuning \n",
    "\n",
    "After your hp tuning has been completed, inspect the results  and print the best model score and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ju5EohREcm92",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "I would change the size the networks to do the hyperparameter tuning but I ran out of time \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCI6YKJicm93"
   },
   "source": [
    "## Task 4: Trees (18pts)\n",
    "The code below generates and shows 4 decision trees trained on a classification problem where the feature matrix $X$ has shape $10,000 \\times 10$  and the outcome has 4 classes labaled 0 through 3.  The feature names are $X_j \\, j = 1 \\dots 10$.  Assume each tree has been trained on a bootstrapped version of the training data and that every feature was available to the tree at every split."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-uMPpPXYcm93",
    "outputId": "290949b0-3469-4ca3-950d-440151863ac6",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = 'tree_0.png')\n",
    "#Outcome : 2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AdxAIKxlcm94",
    "outputId": "43c9587a-616c-4125-fb3e-8cbf668d1130",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "Image(filename = 'tree_1.png')\n",
    "# Outcome: 1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VNo3ys_3cm95",
    "outputId": "ea0c7109-f540-4f63-bbc6-96af823c36b8",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "Image(filename = 'tree_2.png')\n",
    "#Outcome: 0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mNAjLqLfcm95",
    "outputId": "6b1738fc-b807-4dcb-d74c-b3c779634ed9",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "Image(filename = 'tree_3.png')\n",
    "#Outcome = 0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY7KVTxMcm95"
   },
   "source": [
    "### Question 1 (4 pts)  \n",
    "How would each tree classify the following observation? \n",
    "\n",
    "$$\\mathbf{x} = \\begin{bmatrix} \n",
    "1.03\\\\\n",
    "-0.20\\\\\n",
    "2.00\\\\\n",
    "-.99\\\\\n",
    "-0.30\\\\\n",
    "0.15\\\\\n",
    "-.11\\\\\n",
    "5.10\\\\\n",
    "-0.77\\\\\n",
    "0.90\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2IGiT1Hcm95"
   },
   "source": [
    "The following are the classifications that each tree would make:\n",
    "    \n",
    "* Tree_0: X_5 <= -0.47 (observed X_5 = -0.3) -> False -> X_2 <= -0.17 (observed X_2 = -0.20) -> True  -> Class 2\n",
    "*   Tree_1: X_5 <= -0.42 (observed X_5 = -0.3) -> False -> X_2 <= -0.23 (observed X_2 = -0.20) -> False -> Class 1\n",
    "*   Tree_2: X_5 <= -0.03 (observed X_5 = -0.3) -> True  -> X_2 <=  0.32 (observed X_2 = -0.20) -> True  -> Class 0\n",
    "*   Tree_3: X_5 <= -0.24 (observed X_5 = -0.3) -> True  -> X_2 <= -0.32 (observed X_2 = -0.20) -> False -> Class 0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owMaoPDdcm95"
   },
   "source": [
    "### Question 2 (5pts) \n",
    "Together these trees form an ensemble.  What kind is the name of that model?  What are the advantages to using this model over decision trees?  What are the problems with this model?  How would the ensemble classify the observation in part 1?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpf6nugBcm95"
   },
   "source": [
    "\n",
    "This model is called a bagging ensemble\n",
    "\n",
    "Advantages over decision trees:\n",
    "* more stable\n",
    "* exihibit less variance\n",
    "* improved accuracy\n",
    "    \n",
    "Problems with this model:\n",
    "* Can be computationally expensive\n",
    "* model can be hard or impossible to interpret\n",
    "* risk of model being biased if improper procedure isn't followed\n",
    "    \n",
    "The ensemble would classify the observation in part 1 as Class 0. 2 trees \"voted\" for Class 0, which received the most votes (Class 1 & 2 got 1 vote each)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8_qcV9ecm96"
   },
   "source": [
    "### Question 3 (4pts) \n",
    "Write python code that would fit the model described above if you were to be given the training data (Xtrain,ytrain).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-wjYsYdMcm96",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "num_trees = 4\n",
    "tree1 = DecisionTreeClassifier()\n",
    "model_1 = BaggingClassifier(base_estimator = tree1, n_estimators = num_trees, random_state = 0)\n",
    "model_1.fit(x_train, y_train)\n",
    "y_p1 = model_1.predict(x_test)\n",
    "bag_accuracy = accuracy_score(y_test, y_p1)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AttIIvj1cm96"
   },
   "source": [
    "### Question 4 (5pts) \n",
    "Suppose you trained this model and were unsatisfied with the performance.  What would be the next tree based model you would try?  Explain how this model works as if you were talking to a fellow data scientist and why it improves upon the model in part 2 (in theory). In your explanation, highlight similarities and differences between your chosen model and the model in part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvx2NCbLcm96"
   },
   "source": [
    "The next model I would try would be a boosting ensemble, specifically Adaboost. \n",
    "\n",
    "How it works & why it improves on Bagging ensembles.\n",
    "\n",
    "Like bagging ensembles, boosting ensembles (like Adaboost) use multiple trees to make decisions. However, in boosting \n",
    "ensembles, each decision tree is given a specific weight, so when each tree \"votes\" not all votes are counted equally\n",
    "this way, weaker predictors are given less weight than stronger ones. This theoretically improves the accuracy of the\n",
    "model in general. The weights for each tree in a boosted model are determined by sequentially training the decision \n",
    "trees, rather than in parallel like in the bagging model. Each sequential decision tree's success at classifying the \n",
    "data is incorporated into the next decision tree, by updating the weights of the data being used. Once updated, the data\n",
    "is then fed into the next tree and the process is repeated until all desired trees have been generated.\n",
    "\n",
    "\n",
    "Source: https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/"
   ]
  }
 ]
}