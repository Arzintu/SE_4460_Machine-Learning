{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 03: Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw a line plot, use seaborns lineplot and pass in the input and output. Parameters include:\n",
    "\n",
    "x, y vectors or keys in data\n",
    "Variables that specify positions on the x and y axes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-688c82b13165>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xp' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(xp[:,0],yp1)\n",
    "ax=sns.lineplot(recall,precision)\n",
    "ax.set(xlabel=\"Recall\",ylabel=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train_test_split** is part of the 'sklearn.model_selection' library. It allows you to create input and output test and training data given an array of features and an array of a target. In the example below, y is the target column and X is the feature columns. The test_size parameter is used to set how much of the dataset to include in the test data (by default the test size is set to 0.25). The random_state controls the randomization technique (usually always set to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.Class.values\n",
    "X = df.drop(labels = 'Class', axis=1).values\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** is part of the 'sklearn.linear_model'. It is a logistic regression classifier used for classification problems. It has different solvers for different penalities that are applied:\n",
    "- For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "- For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "- ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "- ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "- ‘saga’ also supports ‘elasticnet’ penalty\n",
    "- ‘liblinear’ does not support setting penalty='none'\n",
    "\n",
    "The penalty is applied by default by using the L2 (Ridge) cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(solver = 'lbfgs', penalty='none', max_iter = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have created your **Logistic Regression Model**, you can use it to fit some training data. This will fit your input and output training data against the sigmoid function to classify values. **important: Use slicing instead of df.ColumnName.values to retain column names** (start, stop, [,step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrainamount = xtrain[:, [29]]\n",
    "Xtestamount = xtest[:, [29]]\n",
    "\n",
    "logisticAmount = logisticRegression.fit(Xtrainamount, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use that fitted logistic regression function to predict future values by passing in your test data by using the **predict() method. The predict() method returns class labels for samples in X, while predict_proba() predicts the logarithm of probability estimates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = logisticAmount.predict(test_data.reshape(-1, 1))\n",
    "predict_proba = logisticAmount.predict_proba(test_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the coefficients from the fitted logistic regression model, use the **.coef_ attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGREG = LogisticRegression(penalty = 'none',max_iter=10000)\n",
    "lr_all = LOGREG.fit(Xtrain,ytrain)\n",
    "lr_all.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve a list of the class labels that are known by the classifier, use the **.classes_** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_all.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn metrics library includes objects for the confusion matrix, roc curve, precision recall curve and auc. The AUC object returns fpr: Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]. and tpr: Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(ytest, ytest_prob_amount[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision_recall_curve returns precision, recall when given the training data and predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(ytest, ytest_prob_amount[:,1], pos_label=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 04: Confidence Intervals and Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing **scipy.stats scipy.stats.ppf()** lets you calculate the inverse of the cdf (Given the probability of x, what is my x?) You pass in the quantile followed by the number of degrees of freedom (Number of samples - 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t_quantile = t.ppf(1 - alpha / 2, df = n - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the mean of a given dataset, you can simply use the **.method()** on a data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_mean = data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the lower and upper bounds of the 95% confidence interval for the mean of data, you can use the **.std()** method on the data while passing in parameters including the degrees of freedom and the denominator of the estimated standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " estimated_se = data.std(ddof=1)/np.sqrt(data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the standard error term, we can calculate the bounds by following the equation $$ \\bar{x} \\pm  t_{1-\\alpha/2, n-1} \\dfrac{\\hat{\\sigma}}{\\sqrt{n}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = estimated_mean + t_quantile*estimated_se*np.array([-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **draw random samples from the population** use **np.random.normal()**. This function will allow you to specify number of observations with the size parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(size = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to fit a model, the value must be a 2D array. If you want to train the model based on your input test data, use **np.c_[]** to make it 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(66, 80, 30)\n",
    "y_test = model.predict(np.c_[x_test]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample from the population for bootstrapping, use the **.sample()** method by passing in the number of samples and whether you want replacement or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.sample(n, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the intercept and the coefficients (parameters) from the fitted model use **.intercept_ and .coef_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_fit,d.wt)\n",
    "theta[i,0]=regr.intercept_\n",
    "theta[i,1]=regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 05: Model Selection & Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert categorical data associated with a feature by using the **pd.Categorical()** method in pandas. It takes the model data column and a set of categories in a string array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['work_rate_att'] = pd.Categorical(model_data.work_rate_att, categories=['Low','Medium','High'])\n",
    "model_data['work_rate_def'] = pd.Categorical(model_data.work_rate_def, categories=['Low','Medium','High'])\n",
    "model_data['preferred_foot'] = pd.Categorical(model_data.preferred_foot, categories = ['Left','Right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert columns into dummy variables, use the **pd.get_dummies()** method. Parameters include data: data of which to get the dummy variables for and drop_first, which drops the rest of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies, dropping the first category\n",
    "model_data = pd.get_dummies(model_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the mean absolute error, the function would be written as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mean absolute error function  \n",
    "def mae(y,ypred):\n",
    "     return abs(y - ypred).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the test_size, use the test_size and cast it as an integer by using the ceiling of the test size, n from the formula: $$ n = \\left(\\frac{1.96 \\sigma_l}{d}\\right)^2$$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = (2*sigma/d)**2\n",
    "test_size = int(np.ceil(test_size))\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,\n",
    "                                                y, \n",
    "                                                test_size = int(np.ceil(test_size)), \n",
    "                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning pipeline allows sticking multiple processes into a single sckit learn estimator. Pipelines can fit, predict, and score like an other estimator (like LinearRegression). To implement a pipeline, first drop the labels and separate the features from the target. StandardScaler subtracts the mean from each of the features and then scales it to the unit variance. Then you can start using your pipeline. In the below example, we're giving the pipeline one process, linearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Pipeline([\n",
    "    ('linear_regression', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the cross validation score, use the cross_val_score from the sklearn.model_selection library. Parameters include estimator (your model), your X which is the data to be fit, and y is your target variable (the variable you're trying to predict), cv is the cross validatation splitting strategy:\n",
    "- None, to use the default 5-fold cross validation,\n",
    "- int, to specify the number of folds in a (Stratified)KFold,\n",
    "- CV splitter,\n",
    "- An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "The scoring parameter scores the model, so we use our mean squared error function we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(model1, Xtrain, ytrain, cv=5, scoring = make_scorer(mae))\n",
    "print(cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PolynomialFeatures** generates a polynomial and interaction features. It takes parameters such as degree, include_bias. The degree is the degree of polynomial features (degree = 2 by default), if include_bias is true then it includes a bias column the feature in which all polynomial powers are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2,include_bias = False)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point estimate uses the mean as an estimation method. To calculate the generalization error, first calculate the test error which is the absolute value of the test data subtracted by the predicted data (which came from the predicted model). Then use the **mean()** method on the test_errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the errors and a point estimate of the generalization error\n",
    "test_errors = np.abs(ytest - ypred)\n",
    "generalization_error = test_errors.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 06: Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a step in a pipeline, use the named_steps['step name'] attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer_step = model_pipeline.named_steps['standardize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To standarize the data, use the **fit_transform method** and pass in the input training data. This will fit the training data and then tranform it, given you back a returned transformed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = standardizer_step.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best tuning parameter, use the **GridSearchCV** as part of the sklearn.model_selection.GridSearchCV library. This function does a search over the specific parameter values and returns the cross-validation results. Parameters include: estimator (your pipline), param_grid a dictionary of values, the scoring, and refit, which refits an estimator using the best found parameters on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'reg__alpha': np.exp(np.linspace(-8,6,15))}\n",
    "gscv = GridSearchCV(pip, param_grid=params, cv=10, scoring = 'neg_mean_squared_error', refit=True)\n",
    "gscv.fit(X_new_train, ytrain)\n",
    "\n",
    "results = pd.DataFrame(gscv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important attributes of the returned gridsearch include the best estimator &&**(.best_estimator_) and best score (.best_score_)**, which is the estimator chose by the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = poly.get_feature_names(Xtrain.columns)\n",
    "all_coefs = np.array(gscv.best_estimator_.named_steps['reg'].coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
